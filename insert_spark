# shell commands to insert data to elasticsearch using spark#

import org.elasticsearch.spark.sql._
import spark.implicits._

#object definition
case class Book(Title:String, Year:String, Author:String)

#mapper function
def mapper(line:String): Book = {

	val fields=line.split(',')

     	val book:Book = Book(fields(1), fields(4), fields(2))

     	return book
	}

#creating RDD
val lines = spark.sparkContext.textFile("./library_data/dest")

#creating Dataframes
val books = lines.map(mapper).toDF()

#saving to elasticsearch
books.saveToEs("my_index/books", Map("es.mapping.id" -> "Title"))
